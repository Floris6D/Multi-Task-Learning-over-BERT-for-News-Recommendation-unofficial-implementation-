#test config
news_encoder:
  cfg_cat:
    num_layers: 2
    hidden_size: 124
    output_size: 25
  cfg_ner:
    num_layers: 2
    hidden_size: 124
    output_size: 3

user_encoder:
  hidden_size: 128

trainer:
  optimizer : adam
  epochs: 1000
  lr_user : 0.001
  lr_news : 0.001
  lr_bert : 0.0001
  batch_size: 128
  skip_ner: False
  skip_cat: False
  skip_gs: False

dataset:
  data_dir: ../../data/ebnerd_large
  history_size: 20
  max_title_length: 30
  npratio: 4
  dataset_fraction: 1

model:
  hidden: 768
  pretrained_model_name: bert-base-multilingual-uncased

wandb: True